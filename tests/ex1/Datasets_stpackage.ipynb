{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time: 9.836477279663086 in s\n",
      "Decoding time: 3.275834083557129 in s\n",
      "Test f1 score: 0.305243514032123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from stpredictions.models.IOKR.model import IOKR\n",
    "from stpredictions.datasets import load_bibtex\n",
    "\n",
    "X, Y, _, _ = load_bibtex()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = IOKR()\n",
    "clf.verbose = 1\n",
    "L = 1e-5\n",
    "clf.fit(X=X_train, Y=Y_train, L=L)\n",
    "Y_pred_test = clf.predict(X_test=X_test, Y_candidates=Y_test)\n",
    "f1_test = f1_score(Y_pred_test, Y_test, average='samples')\n",
    "print( \"Test f1 score:\", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 1, 0],\n",
       "       [0, 1, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.14      0.11        14\n",
      "           1       0.30      0.07      0.12       206\n",
      "           2       0.13      0.17      0.15        24\n",
      "           3       0.97      0.35      0.51       104\n",
      "           4       0.39      0.24      0.30        29\n",
      "           5       0.94      0.47      0.62        62\n",
      "           6       0.43      0.09      0.14       410\n",
      "           7       0.20      0.23      0.21        26\n",
      "           8       0.57      0.04      0.07       355\n",
      "           9       0.80      0.32      0.46        87\n",
      "          10       0.90      0.88      0.89        74\n",
      "          11       0.44      0.22      0.29        79\n",
      "          12       0.08      0.04      0.05        49\n",
      "          13       0.84      1.00      0.91        46\n",
      "          14       0.86      0.92      0.89       166\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.47      0.61      0.53        28\n",
      "          17       0.55      0.03      0.06       329\n",
      "          18       0.76      0.10      0.18       383\n",
      "          19       0.20      0.30      0.24        23\n",
      "          20       0.54      0.03      0.06       381\n",
      "          21       0.85      0.08      0.14       444\n",
      "          22       0.63      0.08      0.14       369\n",
      "          23       0.76      0.16      0.27        99\n",
      "          24       0.68      0.11      0.20       131\n",
      "          25       0.00      0.00      0.00        15\n",
      "          26       0.50      0.73      0.59        22\n",
      "          27       0.57      0.15      0.23       163\n",
      "          28       0.18      0.16      0.17        19\n",
      "          29       0.83      0.12      0.22       121\n",
      "          30       0.30      0.27      0.29        22\n",
      "          31       0.76      0.62      0.68        21\n",
      "          32       0.22      0.17      0.19        40\n",
      "          33       0.29      0.08      0.12        91\n",
      "          34       0.67      0.04      0.08       392\n",
      "          35       0.75      0.90      0.82        30\n",
      "          36       0.62      0.22      0.33       201\n",
      "          37       0.07      0.06      0.06        16\n",
      "          38       0.54      0.25      0.34        60\n",
      "          39       0.26      0.05      0.08       105\n",
      "          40       0.62      0.42      0.50        19\n",
      "          41       0.45      0.11      0.17       255\n",
      "          42       0.51      0.22      0.31        87\n",
      "          43       0.52      0.13      0.21        97\n",
      "          44       0.96      0.54      0.69        93\n",
      "          45       0.08      0.12      0.10         8\n",
      "          46       0.12      0.07      0.09        29\n",
      "          47       0.21      0.12      0.15        50\n",
      "          48       0.26      0.08      0.13        96\n",
      "          49       0.85      0.45      0.59        49\n",
      "          50       0.35      0.15      0.21        53\n",
      "          51       0.04      0.17      0.06         6\n",
      "          52       0.74      0.33      0.45       203\n",
      "          53       0.83      0.12      0.22       121\n",
      "          54       0.72      0.08      0.14       488\n",
      "          55       0.74      0.12      0.21       164\n",
      "          56       0.57      0.08      0.14       159\n",
      "          57       0.71      0.26      0.38        38\n",
      "          58       0.13      0.17      0.15        12\n",
      "          59       0.29      0.31      0.30        13\n",
      "          60       0.08      0.25      0.12         4\n",
      "          61       0.91      0.30      0.45        98\n",
      "          62       0.71      0.55      0.62        22\n",
      "          63       0.85      0.56      0.68       121\n",
      "          64       1.00      0.30      0.46        63\n",
      "          65       0.93      0.27      0.42        93\n",
      "          66       0.22      0.19      0.20        59\n",
      "          67       0.19      0.13      0.15        38\n",
      "          68       0.52      0.14      0.22        85\n",
      "          69       0.33      0.26      0.29        19\n",
      "          70       0.20      0.12      0.16        80\n",
      "          71       0.15      0.40      0.22        10\n",
      "          72       0.60      0.10      0.17       151\n",
      "          73       0.26      0.18      0.21        57\n",
      "          74       0.42      0.50      0.45        10\n",
      "          75       0.82      0.13      0.22       599\n",
      "          76       0.89      0.49      0.63        35\n",
      "          77       0.46      0.56      0.51        32\n",
      "          78       0.19      0.40      0.26        10\n",
      "          79       0.64      0.15      0.25        46\n",
      "          80       0.07      0.07      0.07        43\n",
      "          81       0.60      0.39      0.47        54\n",
      "          82       0.65      0.79      0.71        14\n",
      "          83       0.81      0.51      0.63       101\n",
      "          84       0.67      0.16      0.26       174\n",
      "          85       0.30      0.33      0.32        39\n",
      "          86       0.83      0.43      0.57        46\n",
      "          87       0.76      0.06      0.10       396\n",
      "          88       0.39      0.06      0.10       550\n",
      "          89       0.00      0.00      0.00        11\n",
      "          90       0.17      0.06      0.09        69\n",
      "          91       0.42      0.09      0.15       142\n",
      "          92       0.53      0.14      0.22        74\n",
      "          93       0.69      0.12      0.20       325\n",
      "          94       0.05      0.14      0.07         7\n",
      "          95       0.58      0.09      0.15       159\n",
      "          96       0.69      0.08      0.14       551\n",
      "          97       0.70      0.10      0.17       496\n",
      "          98       0.24      0.50      0.32         8\n",
      "          99       0.24      0.10      0.14        59\n",
      "         100       0.49      0.06      0.10       325\n",
      "         101       0.87      0.30      0.44        87\n",
      "         102       0.35      0.29      0.32        21\n",
      "         103       0.76      0.08      0.15       236\n",
      "         104       0.86      0.10      0.18       618\n",
      "         105       0.54      0.12      0.20       122\n",
      "         106       0.63      0.04      0.07       430\n",
      "         107       0.59      0.18      0.28       128\n",
      "         108       0.44      0.02      0.05       329\n",
      "         109       0.00      0.00      0.00        43\n",
      "         110       0.21      0.22      0.21        27\n",
      "         111       0.21      0.14      0.17        66\n",
      "         112       0.55      0.86      0.67        14\n",
      "         113       0.74      0.35      0.48        82\n",
      "         114       0.33      0.16      0.22        50\n",
      "         115       0.29      0.60      0.39        10\n",
      "         116       0.32      0.08      0.13        75\n",
      "         117       0.58      0.45      0.51        78\n",
      "         118       0.48      0.04      0.07       385\n",
      "         119       0.19      0.10      0.13        71\n",
      "         120       0.24      0.23      0.24        30\n",
      "         121       0.65      0.06      0.11       346\n",
      "         122       0.74      0.18      0.29       324\n",
      "         123       0.27      0.02      0.03       380\n",
      "         124       0.81      0.18      0.30       279\n",
      "         125       0.87      0.39      0.54        33\n",
      "         126       0.44      0.11      0.18       171\n",
      "         127       0.06      0.03      0.04        34\n",
      "         128       0.15      0.02      0.04       141\n",
      "         129       0.68      0.11      0.18       473\n",
      "         130       0.53      0.03      0.05       335\n",
      "         131       0.83      0.20      0.32       567\n",
      "         132       0.83      0.22      0.35        85\n",
      "         133       0.30      0.02      0.03       348\n",
      "         134       1.00      0.87      0.93       426\n",
      "         135       0.43      0.04      0.07       406\n",
      "         136       0.10      0.05      0.06        43\n",
      "         137       0.33      0.02      0.04       376\n",
      "         138       0.25      0.09      0.13       136\n",
      "         139       0.78      0.08      0.14       492\n",
      "         140       0.18      0.14      0.15        22\n",
      "         141       0.29      0.08      0.13       214\n",
      "         142       0.19      0.38      0.25        16\n",
      "         143       0.52      0.33      0.41        66\n",
      "         144       0.40      0.41      0.40        54\n",
      "         145       0.53      0.26      0.35        72\n",
      "         146       0.38      0.31      0.34        64\n",
      "         147       0.06      0.50      0.10         2\n",
      "         148       0.12      0.14      0.13        21\n",
      "         149       0.53      0.33      0.41        69\n",
      "         150       0.50      0.38      0.43        26\n",
      "         151       0.56      0.43      0.48        35\n",
      "         152       0.18      0.07      0.10       113\n",
      "         153       0.52      0.13      0.21       108\n",
      "         154       0.56      0.48      0.51        21\n",
      "         155       0.36      0.29      0.32        49\n",
      "         156       0.63      0.17      0.27       279\n",
      "         157       0.52      0.03      0.06       435\n",
      "         158       0.35      0.29      0.32        21\n",
      "\n",
      "   micro avg       0.57      0.15      0.23     22538\n",
      "   macro avg       0.48      0.23      0.27     22538\n",
      "weighted avg       0.60      0.15      0.21     22538\n",
      " samples avg       0.55      0.24      0.31     22538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_pred_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records for train (4954, 1836)\n",
      "Number of records for test (2441, 1836)\n",
      "Number of records for train (4954, 159)\n",
      "Number of records for test (2441, 159)\n",
      "4954 train samples\n",
      "2441 test samples\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('Number of records for train',X_train.shape)\n",
    "print('Number of records for test',X_test.shape)\n",
    "print('Number of records for train',Y_train.shape)\n",
    "print('Number of records for test',Y_test.shape)\n",
    "\n",
    "# Number of data set samples \n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    " \n",
    "# Data format confirmation\n",
    "print(type(X_test))\n",
    "print(type(Y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7395, 159)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_or = X_train\n",
    "X_train = X_train.reshape(4954*1836)\n",
    "Y_train_or= Y_train\n",
    "Y_train= Y_train.reshape(4954*159)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4954, 787686]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/Documents/AA_Télécom/HiParis/Project/PROJECT/structured-predictions/ex1/Datasets_stpackage.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/daniel/Documents/AA_T%C3%A9l%C3%A9com/HiParis/Project/PROJECT/structured-predictions/ex1/Datasets_stpackage.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m logreg \u001b[39m=\u001b[39m  LogisticRegression()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/daniel/Documents/AA_T%C3%A9l%C3%A9com/HiParis/Project/PROJECT/structured-predictions/ex1/Datasets_stpackage.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m logreg\u001b[39m.\u001b[39;49mfit(X_train_or,Y_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1506\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[0;32m-> 1508\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1509\u001b[0m     X,\n\u001b[1;32m   1510\u001b[0m     y,\n\u001b[1;32m   1511\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1512\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[1;32m   1513\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1514\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1515\u001b[0m )\n\u001b[1;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1517\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:981\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    965\u001b[0m     X,\n\u001b[1;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    977\u001b[0m )\n\u001b[1;32m    979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[0;32m--> 981\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m    983\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    333\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    335\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4954, 787686]"
     ]
    }
   ],
   "source": [
    "logreg =  LogisticRegression()\n",
    "logreg.fit(X_train_or,Y_train) ## fitting the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting time: 1.0211117267608643 in s\n",
      "Decoding time: 0.4390690326690674 in s\n",
      "Test f1 score: 0.24521404521404525\n"
     ]
    }
   ],
   "source": [
    "from stpredictions.datasets import load_corel5k\n",
    "\n",
    "X, Y, _, _ = load_corel5k()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = IOKR()\n",
    "clf.verbose = 1\n",
    "L = 1e-5\n",
    "clf.fit(X=X_train, Y=Y_train, L=L)\n",
    "Y_pred_test = clf.predict(X_test=X_test, Y_candidates=Y_test)\n",
    "f1_test = f1_score(Y_pred_test, Y_test, average='samples')\n",
    "print( \"Test f1 score:\", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records for train (3350, 499)\n",
      "Number of records for test (1650, 499)\n",
      "Number of records for train (3350, 374)\n",
      "Number of records for test (1650, 374)\n",
      "3350 train samples\n",
      "1650 test samples\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('Number of records for train',X_train.shape)\n",
    "print('Number of records for test',X_test.shape)\n",
    "print('Number of records for train',Y_train.shape)\n",
    "print('Number of records for test',Y_test.shape)\n",
    "\n",
    "# Number of data set samples \n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    " \n",
    "# Data format confirmation\n",
    "print(type(X_test))\n",
    "print(type(Y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1252900 into shape (3350,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Y_train_rshp\u001b[38;5;241m=\u001b[39m \u001b[43mY_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3350\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1252900 into shape (3350,)"
     ]
    }
   ],
   "source": [
    "Y_train_rshp= Y_train.reshape(3350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (3350, 374) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m logreg \u001b[38;5;241m=\u001b[39m  LogisticRegression()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mlogreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1506\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1508\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:979\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    964\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    965\u001b[0m     X,\n\u001b[1;32m    966\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    976\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    977\u001b[0m )\n\u001b[0;32m--> 979\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[1;32m    989\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    990\u001b[0m         y, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     )\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 993\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m     _assert_all_finite(y)\n\u001b[1;32m    995\u001b[0m     _ensure_no_complex_data(y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1038\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1030\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1031\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expected. Please change the shape of y to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1035\u001b[0m         )\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[0;32m-> 1038\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1040\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (3350, 374) instead."
     ]
    }
   ],
   "source": [
    "logreg =  LogisticRegression()\n",
    "logreg.fit(X_train,Y_train) ## fitting the logistic regression model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ad57050c77180dc9ed5ccc7774a474d285089782a3b5193155c6c81d567ba30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
